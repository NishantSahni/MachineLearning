{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model For Predicting The Class of Wheat Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Nishant Sahni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from math import ceil, floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will now be loaded onto a pandas dataframe using the read_table() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('/Users/Nishant/Desktop/Machine Learning/Exam/classification_wheat_kernel_data.txt', \n",
    "                     delim_whitespace=True, header=0, names=('area', 'perimeter', 'compactness', \n",
    "                                                             'kernel_length', 'kernel_width', 'asym', \n",
    "                                                             'groove_length', 'type'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary statistics of the data will then be examined with the help of the following code. The data.corr() function gives the correlation of every feature with every other feature. The data.describe() function gives some summary statistics for each feature including count, mean, minimum value, maximum value, etc. The data.isna() is used to determine if there are any missing values or erroneous values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['area', 'perimeter', 'compactness', 'kernel_length', 'kernel_width',\n",
      "       'asym', 'groove_length', 'type'],\n",
      "      dtype='object')\n",
      "             area   perimeter  compactness  kernel_length  kernel_width  \\\n",
      "count  210.000000  210.000000   210.000000     210.000000    210.000000   \n",
      "mean    14.847524   14.559286     0.870999       5.628533      3.258605   \n",
      "std      2.909699    1.305959     0.023629       0.443063      0.377714   \n",
      "min     10.590000   12.410000     0.808100       4.899000      2.630000   \n",
      "25%     12.270000   13.450000     0.856900       5.262250      2.944000   \n",
      "50%     14.355000   14.320000     0.873450       5.523500      3.237000   \n",
      "75%     17.305000   15.715000     0.887775       5.979750      3.561750   \n",
      "max     21.180000   17.250000     0.918300       6.675000      4.033000   \n",
      "\n",
      "             asym  groove_length        type  \n",
      "count  210.000000     210.000000  210.000000  \n",
      "mean     3.700201       5.408071    2.000000  \n",
      "std      1.503557       0.491480    0.818448  \n",
      "min      0.765100       4.519000    1.000000  \n",
      "25%      2.561500       5.045000    1.000000  \n",
      "50%      3.599000       5.223000    2.000000  \n",
      "75%      4.768750       5.877000    3.000000  \n",
      "max      8.456000       6.550000    3.000000  \n",
      "                   area  perimeter  compactness  kernel_length  kernel_width  \\\n",
      "area           1.000000   0.994341     0.608288       0.949985      0.970771   \n",
      "perimeter      0.994341   1.000000     0.529244       0.972422      0.944829   \n",
      "compactness    0.608288   0.529244     1.000000       0.367915      0.761635   \n",
      "kernel_length  0.949985   0.972422     0.367915       1.000000      0.860415   \n",
      "kernel_width   0.970771   0.944829     0.761635       0.860415      1.000000   \n",
      "asym          -0.229572  -0.217340    -0.331471      -0.171562     -0.258037   \n",
      "groove_length  0.863693   0.890784     0.226825       0.932806      0.749131   \n",
      "type          -0.346058  -0.327900    -0.531007      -0.257269     -0.423463   \n",
      "\n",
      "                   asym  groove_length      type  \n",
      "area          -0.229572       0.863693 -0.346058  \n",
      "perimeter     -0.217340       0.890784 -0.327900  \n",
      "compactness   -0.331471       0.226825 -0.531007  \n",
      "kernel_length -0.171562       0.932806 -0.257269  \n",
      "kernel_width  -0.258037       0.749131 -0.423463  \n",
      "asym           1.000000      -0.011079  0.577273  \n",
      "groove_length -0.011079       1.000000  0.024301  \n",
      "type           0.577273       0.024301  1.000000  \n",
      "      area  perimeter  compactness  kernel_length  kernel_width   asym  \\\n",
      "0    False      False        False          False         False  False   \n",
      "1    False      False        False          False         False  False   \n",
      "2    False      False        False          False         False  False   \n",
      "3    False      False        False          False         False  False   \n",
      "4    False      False        False          False         False  False   \n",
      "5    False      False        False          False         False  False   \n",
      "6    False      False        False          False         False  False   \n",
      "7    False      False        False          False         False  False   \n",
      "8    False      False        False          False         False  False   \n",
      "9    False      False        False          False         False  False   \n",
      "10   False      False        False          False         False  False   \n",
      "11   False      False        False          False         False  False   \n",
      "12   False      False        False          False         False  False   \n",
      "13   False      False        False          False         False  False   \n",
      "14   False      False        False          False         False  False   \n",
      "15   False      False        False          False         False  False   \n",
      "16   False      False        False          False         False  False   \n",
      "17   False      False        False          False         False  False   \n",
      "18   False      False        False          False         False  False   \n",
      "19   False      False        False          False         False  False   \n",
      "20   False      False        False          False         False  False   \n",
      "21   False      False        False          False         False  False   \n",
      "22   False      False        False          False         False  False   \n",
      "23   False      False        False          False         False  False   \n",
      "24   False      False        False          False         False  False   \n",
      "25   False      False        False          False         False  False   \n",
      "26   False      False        False          False         False  False   \n",
      "27   False      False        False          False         False  False   \n",
      "28   False      False        False          False         False  False   \n",
      "29   False      False        False          False         False  False   \n",
      "..     ...        ...          ...            ...           ...    ...   \n",
      "180  False      False        False          False         False  False   \n",
      "181  False      False        False          False         False  False   \n",
      "182  False      False        False          False         False  False   \n",
      "183  False      False        False          False         False  False   \n",
      "184  False      False        False          False         False  False   \n",
      "185  False      False        False          False         False  False   \n",
      "186  False      False        False          False         False  False   \n",
      "187  False      False        False          False         False  False   \n",
      "188  False      False        False          False         False  False   \n",
      "189  False      False        False          False         False  False   \n",
      "190  False      False        False          False         False  False   \n",
      "191  False      False        False          False         False  False   \n",
      "192  False      False        False          False         False  False   \n",
      "193  False      False        False          False         False  False   \n",
      "194  False      False        False          False         False  False   \n",
      "195  False      False        False          False         False  False   \n",
      "196  False      False        False          False         False  False   \n",
      "197  False      False        False          False         False  False   \n",
      "198  False      False        False          False         False  False   \n",
      "199  False      False        False          False         False  False   \n",
      "200  False      False        False          False         False  False   \n",
      "201  False      False        False          False         False  False   \n",
      "202  False      False        False          False         False  False   \n",
      "203  False      False        False          False         False  False   \n",
      "204  False      False        False          False         False  False   \n",
      "205  False      False        False          False         False  False   \n",
      "206  False      False        False          False         False  False   \n",
      "207  False      False        False          False         False  False   \n",
      "208  False      False        False          False         False  False   \n",
      "209  False      False        False          False         False  False   \n",
      "\n",
      "     groove_length   type  \n",
      "0            False  False  \n",
      "1            False  False  \n",
      "2            False  False  \n",
      "3            False  False  \n",
      "4            False  False  \n",
      "5            False  False  \n",
      "6            False  False  \n",
      "7            False  False  \n",
      "8            False  False  \n",
      "9            False  False  \n",
      "10           False  False  \n",
      "11           False  False  \n",
      "12           False  False  \n",
      "13           False  False  \n",
      "14           False  False  \n",
      "15           False  False  \n",
      "16           False  False  \n",
      "17           False  False  \n",
      "18           False  False  \n",
      "19           False  False  \n",
      "20           False  False  \n",
      "21           False  False  \n",
      "22           False  False  \n",
      "23           False  False  \n",
      "24           False  False  \n",
      "25           False  False  \n",
      "26           False  False  \n",
      "27           False  False  \n",
      "28           False  False  \n",
      "29           False  False  \n",
      "..             ...    ...  \n",
      "180          False  False  \n",
      "181          False  False  \n",
      "182          False  False  \n",
      "183          False  False  \n",
      "184          False  False  \n",
      "185          False  False  \n",
      "186          False  False  \n",
      "187          False  False  \n",
      "188          False  False  \n",
      "189          False  False  \n",
      "190          False  False  \n",
      "191          False  False  \n",
      "192          False  False  \n",
      "193          False  False  \n",
      "194          False  False  \n",
      "195          False  False  \n",
      "196          False  False  \n",
      "197          False  False  \n",
      "198          False  False  \n",
      "199          False  False  \n",
      "200          False  False  \n",
      "201          False  False  \n",
      "202          False  False  \n",
      "203          False  False  \n",
      "204          False  False  \n",
      "205          False  False  \n",
      "206          False  False  \n",
      "207          False  False  \n",
      "208          False  False  \n",
      "209          False  False  \n",
      "\n",
      "[210 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "data.head()\n",
    "print(data.keys())\n",
    "\n",
    "print(data.describe())\n",
    "print(data.corr())\n",
    "print(data.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By examining the above information we determine that the data has missing values and examine the data set to find unformatted information. This is then rectified before we proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we move on to obtain the correlation of every feature with the target (type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area -0.3460578672033167\n",
      "perimeter -0.32789969778257677\n",
      "compactness -0.5310070238941204\n",
      "kernel_length -0.2572687006481211\n",
      "kernel_width -0.4234628716721287\n",
      "asym 0.5772727110447099\n",
      "groove_length 0.024301043067281567\n"
     ]
    }
   ],
   "source": [
    "for item in data:\n",
    "\tif item != 'type':\n",
    "\t\tcorr = float(data[item].corr(data['type']))\n",
    "\t\tprint(item, corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring the information above it is decided to not drop any features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (pd.DataFrame(data, columns=(['area', 'perimeter', 'compactness', 'kernel_length', 'kernel_width', 'asym', 'groove_length']))).as_matrix()\n",
    "y = (pd.DataFrame(data, columns=(['type']))).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, the X and y values are then loaded from the data set. This data is then split into training and testing set by a 80:20 split. This is done so that the model can be trained with the training data and the prediction accuracy can be measured with respect to the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply Logistic Regression to our data and use GridSearchCV to perform 5-Fold cross validation and to select the best parameters. Cross validation is used to avoid over fitting by training multiple models on a certain number of subsets of the data and then evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "logreg = GridSearchCV(log, cv=5, param_grid={})\n",
    "logreg.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation score and a few other statistics are then obtained for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCORES FOR LOGISTIC REGRESSION:\n",
      "\n",
      "Gridsearch CV score:  0.89880952381\n",
      "Training set score:  0.922619047619\n",
      "Linear accuracy score:  0.952380952381\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"SCORES FOR LOGISTIC REGRESSION:\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Gridsearch CV score: \", logreg.best_score_)\n",
    "print(\"Training set score: \", logreg.score(x_train, y_train))\n",
    "print(\"Linear accuracy score: \", logreg.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the test data with our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters selected by GridSearchCV and the prediction scores for Logistic Regression are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Selected:  {}\n",
      "Accuracy score for the prediction:  0.952380952381\n",
      "Confusion Matrix:\n",
      "[[14  1  1]\n",
      " [ 0 16  0]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters Selected: \", logreg.best_params_)\n",
    "print(\"Accuracy score for the prediction: \", accuracy_score(y_test, predictions))\n",
    "print(\"Confusion Matrix:\") \n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, the accuracy score and confusion matrix was obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (Hard and Soft Margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try both hard and soft margin SVM with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svm_soft = GridSearchCV(svc, cv=5, param_grid={'C': [0.1, 0.5, 1, 2, 5], 'kernel': ['linear', 'poly', 'rbf']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above code, the best parameters for Soft Margin SVM were to be selected using GridSearchCV, and 5-fold cross validation was used. The values of C can be 0.1, 0.5, 1, 2 or 5, as specified in the question, and the kernels can be picked between linear, polynomial and gaussian. We then train the model with our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 0.5, 1, 2, 5], 'kernel': ['linear', 'poly', 'rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_soft.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of scores is then obtained for our model including the cross validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCORES FOR SOFT MARGIN SVM:\n",
      "\n",
      "Gridsearch CV score:  0.964285714286\n",
      "Training set score:  0.988095238095\n",
      "Linear accuracy score:  0.97619047619\n",
      "Best Parameters Selected:  {'C': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"SCORES FOR SOFT MARGIN SVM:\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Gridsearch CV score: \", svm_soft.best_score_)\n",
    "print(\"Training set score: \", svm_soft.score(x_train, y_train))\n",
    "print(\"Linear accuracy score: \", svm_soft.score(x_test, y_test))\n",
    "print(\"Best Parameters Selected: \", svm_soft.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above that the best parameters selected for Soft Margin SVM by GridSearchCV are C = 1 and kernel = polynomial.\n",
    "\n",
    "The test data was then predicted with our trained SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_soft_predictions = svm_soft.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some prediction scores are then obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the prediction:  0.97619047619\n",
      "Confusion Matrix:\n",
      "[[15  0  1]\n",
      " [ 0 16  0]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for the prediction: \", accuracy_score(y_test, svm_soft_predictions))\n",
    "print(\"Confusion Matrix:\") \n",
    "print(confusion_matrix(y_test, svm_soft_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction accuracy score and confusion matrix are then obtained as seen above.\n",
    "\n",
    "We next move on to try Hard Margin SVM with our data. GridSearchCV is used to select between C values of 100 or 1000, and linear, polynomial or gaussian kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hard = GridSearchCV(svc, cv=5, param_grid={'C': [100, 1000], 'kernel': ['linear', 'poly', 'rbf']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [100, 1000], 'kernel': ['linear', 'poly', 'rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_hard.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch cross validation score and the best hyperparameters selected are shown as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCORES FOR HARD MARGIN SVM:\n",
      "\n",
      "Gridsearch CV score:  0.964285714286\n",
      "Training set score:  1.0\n",
      "Linear accuracy score:  0.97619047619\n",
      "Best Parameters Selected:  {'C': 100, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"SCORES FOR HARD MARGIN SVM:\")\n",
    "print(\"\")\n",
    "print(\"Gridsearch CV score: \", svm_hard.best_score_)\n",
    "print(\"Training set score: \", svm_hard.score(x_train, y_train))\n",
    "print(\"Linear accuracy score: \", svm_hard.score(x_test, y_test))\n",
    "print(\"Best Parameters Selected: \", svm_hard.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of C is selected as 100 and the kernel is selected as polynomial by GridSearchCV. We then make predictions based on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hard_predictions = svm_hard.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score for the prediction and the confusion matrix is then obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the prediction:  0.97619047619\n",
      "Confusion Matrix:\n",
      "[[15  0  1]\n",
      " [ 0 16  0]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for the prediction: \", accuracy_score(y_test, svm_hard_predictions))\n",
    "print(\"Confusion Matrix:\") \n",
    "print(confusion_matrix(y_test, svm_hard_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernalized Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A modified version of Kernalized Ridge is then attempted where the results are normalized so as to be applicable for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernreg = KernelRidge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and testing data is then normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normalized = normalize(x_train, norm='l2')\n",
    "x_test_normalized = normalize(x_test, norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV is then used with 5-fold cross validation along with the specified parameters to obtain the best ones. The model is then trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
       "      kernel_params=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kernel': ['linear']}, {'alpha': [1], 'kernel': ['poly'], 'gamma': [1], 'degree': [2, 3, 4]}, {'kernel': ['rbf'], 'gamma': [0.1, 0.5, 1, 2, 4]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = GridSearchCV(kernreg, cv=5, param_grid=[{'kernel': ['linear']}, {'alpha': [1], 'kernel': ['poly'], 'gamma': [1], 'degree': [2, 3, 4]}, {'kernel': ['rbf'], 'gamma': [0.1, 0.5, 1, 2, 4]}])\n",
    "ridge.fit(x_train_normalized, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series of scores are then obtained. Also we can see below the parameter values selected by GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCORES FOR KERNALIZED RIDGE:\n",
      "\n",
      "Gridsearch score:  0.515191774704\n",
      "Training set score:  0.564450288044\n",
      "Linear accuracy score:  0.521164690278\n",
      "Best Parameters Selected:  {'alpha': 1, 'degree': 4, 'gamma': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"SCORES FOR KERNALIZED RIDGE:\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Gridsearch score: \", ridge.best_score_)\n",
    "print(\"Training set score: \", ridge.score(x_train_normalized, y_train))\n",
    "print(\"Linear accuracy score: \", ridge.score(x_test_normalized, y_test))\n",
    "print(\"Best Parameters Selected: \", ridge.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters selected by GridSearchCV are shown above. We then predict the class and normalize the results to obtain the accuracy score and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_predictions = ridge.predict(x_test_normalized)\n",
    "ridge_predictions = ridge_predictions.tolist()\n",
    "for i in range(0, len(ridge_predictions), 1):\n",
    "\tif ridge_predictions[i] < 1 or ridge_predictions[i] > 1.5 or ridge_predictions[i] > 2.5:\n",
    "\t\tridge_predictions[i] = ceil(ridge_predictions[i])\n",
    "\telse:\n",
    "\t\tridge_predictions[i] = floor(ridge_predictions[i])\n",
    "\n",
    "ridge_predictions = np.asarray(ridge_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following scores are obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the prediction:  0.52380952381\n",
      "Confusion Matrix:\n",
      "[[5 8 3 0]\n",
      " [3 9 4 0]\n",
      " [0 0 8 2]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for the prediction: \", accuracy_score(y_test, ridge_predictions))\n",
    "print(\"Confusion Matrix:\") \n",
    "print(confusion_matrix(y_test, ridge_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By observing the accuracy scores and confusion matrices for the models, it is concluded that both, Hard Margin SVM with C = 100 and a polynomial kernel, and Soft Margin SVM with a polynomial kernel and C = 1 are good models for this data where both give an accuracy score of 0.97619047619. The accuracy score is a measure of the correct predictions made in comparision to the total number of predictions made. The confusion matrix on the other hand, is a matrix which shows the actual predictions on the x axis and the accuracy on the y axis. The cells represent the total number of predictions made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
