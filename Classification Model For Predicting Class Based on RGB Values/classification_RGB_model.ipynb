{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model For Predicting Class Labels Based on B, G and R Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Nishant Sahni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from math import ceil, floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is first loaded onto a pandas dataframe and some summary statistics are obtained. The correlation between attribute columns is also obtained. The data.describe() function gives some summary statistics for each feature including count, mean, minimum value, maximum value, etc. The data.isna() is used to determine if there are any missing values or erroneous values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Red', 'Green', 'Blue', 'Class'], dtype='object')\n",
      "                 Red          Green           Blue          Class\n",
      "count  245057.000000  245057.000000  245057.000000  245057.000000\n",
      "mean      125.065446     132.507327     123.177151       1.792461\n",
      "std        62.255653      59.941197      72.562165       0.405546\n",
      "min         0.000000       0.000000       0.000000       1.000000\n",
      "25%        68.000000      87.000000      70.000000       2.000000\n",
      "50%       139.000000     153.000000     128.000000       2.000000\n",
      "75%       176.000000     177.000000     164.000000       2.000000\n",
      "max       255.000000     255.000000     255.000000       2.000000\n",
      "            Red     Green      Blue     Class\n",
      "Red    1.000000  0.855250  0.496376  0.092030\n",
      "Green  0.855250  1.000000  0.660098 -0.120327\n",
      "Blue   0.496376  0.660098  1.000000 -0.569958\n",
      "Class  0.092030 -0.120327 -0.569958  1.000000\n",
      "          Red  Green   Blue  Class\n",
      "0       False  False  False  False\n",
      "1       False  False  False  False\n",
      "2       False  False  False  False\n",
      "3       False  False  False  False\n",
      "4       False  False  False  False\n",
      "5       False  False  False  False\n",
      "6       False  False  False  False\n",
      "7       False  False  False  False\n",
      "8       False  False  False  False\n",
      "9       False  False  False  False\n",
      "10      False  False  False  False\n",
      "11      False  False  False  False\n",
      "12      False  False  False  False\n",
      "13      False  False  False  False\n",
      "14      False  False  False  False\n",
      "15      False  False  False  False\n",
      "16      False  False  False  False\n",
      "17      False  False  False  False\n",
      "18      False  False  False  False\n",
      "19      False  False  False  False\n",
      "20      False  False  False  False\n",
      "21      False  False  False  False\n",
      "22      False  False  False  False\n",
      "23      False  False  False  False\n",
      "24      False  False  False  False\n",
      "25      False  False  False  False\n",
      "26      False  False  False  False\n",
      "27      False  False  False  False\n",
      "28      False  False  False  False\n",
      "29      False  False  False  False\n",
      "...       ...    ...    ...    ...\n",
      "245027  False  False  False  False\n",
      "245028  False  False  False  False\n",
      "245029  False  False  False  False\n",
      "245030  False  False  False  False\n",
      "245031  False  False  False  False\n",
      "245032  False  False  False  False\n",
      "245033  False  False  False  False\n",
      "245034  False  False  False  False\n",
      "245035  False  False  False  False\n",
      "245036  False  False  False  False\n",
      "245037  False  False  False  False\n",
      "245038  False  False  False  False\n",
      "245039  False  False  False  False\n",
      "245040  False  False  False  False\n",
      "245041  False  False  False  False\n",
      "245042  False  False  False  False\n",
      "245043  False  False  False  False\n",
      "245044  False  False  False  False\n",
      "245045  False  False  False  False\n",
      "245046  False  False  False  False\n",
      "245047  False  False  False  False\n",
      "245048  False  False  False  False\n",
      "245049  False  False  False  False\n",
      "245050  False  False  False  False\n",
      "245051  False  False  False  False\n",
      "245052  False  False  False  False\n",
      "245053  False  False  False  False\n",
      "245054  False  False  False  False\n",
      "245055  False  False  False  False\n",
      "245056  False  False  False  False\n",
      "\n",
      "[245057 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_table('/Users/Nishant/Desktop/Machine Learning/Exam/classification_data.tsv', delim_whitespace=True, header=0)\n",
    "data.head()\n",
    "print(data.keys())\n",
    "print(data.describe())\n",
    "print(data.corr())\n",
    "print(data.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the above information the correlation between each feature and the target (Class) is obtained to further analyse the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red 0.0920300916444954\n",
      "Green -0.12032744045817019\n",
      "Blue -0.5699582232198895\n"
     ]
    }
   ],
   "source": [
    "for item in data:\n",
    "\tif item != 'Class':\n",
    "\t\tcorr = float(data[item].corr(data['Class']))\n",
    "\t\tprint(item, corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the above data, and decide to not drop any features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The X and y values are then loaded onto a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (pd.DataFrame(data, columns=(['Red', 'Blue', 'Green']))).as_matrix()\n",
    "y = (pd.DataFrame(data, columns=(['Class']))).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is then split into train and test set by a 80:20 split. This is done so that the model can be trained with the training data and the prediction accuracy can be measured with respect to the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is first tried on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV is then used to conduct 5-fold cross validation and to determine the hyperparameter C value. Cross validation is used to avoid over fitting by training multiple models on a certain number of subsets of the data and then evaluating the model. The training data is then used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = GridSearchCV(log, cv=5, param_grid={'C': [0.1, 1, 10, 100, 1000]})\n",
    "logreg.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation score and some other statistics are obtained as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCORES FOR LOGISTIC REGRESSION:\n",
      "\n",
      "Gridsearch CV score:  0.918896171797\n",
      "Training set score:  0.918885970058\n",
      "Linear accuracy score:  0.918672978046\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"SCORES FOR LOGISTIC REGRESSION:\")\n",
    "print(\"\")\n",
    "print(\"Gridsearch CV score: \", logreg.best_score_)\n",
    "print(\"Training set score: \", logreg.score(x_train, y_train))\n",
    "print(\"Linear accuracy score: \", logreg.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data is then used to predict the class with the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters selected by GridSearchCV, the accuracy score of the model and the confusion matrix are then obtained as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Selected:  {'C': 0.1}\n",
      "Accuracy score for the prediction:  0.918672978046\n",
      "Confusion Matrix:\n",
      "[[ 8494  1854]\n",
      " [ 2132 36532]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters Selected: \", logreg.best_params_)\n",
    "print(\"Accuracy score for the prediction: \", accuracy_score(y_test, predictions))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (Hard and Soft Margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next SVC is tried with the data, both hard and soft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV is used to determine the C values from the list provided in the question and the kernel between linear, polynomial or gaussian. GridSearchCV also conducts 5-fold cross validation. The hardness or softness of SVM depends on the value of C selected. The higher the value selected the harder the margin. 100 and 1000 are values added to param_grid for C to check for Hard Margin SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = GridSearchCV(svc, cv=5, param_grid={'C': [0.1, 0.5, 1, 2, 5, 100, 1000], 'kernel': ['linear', 'poly', 'rbf']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is then normalized to improve performance with SVM and decrease convergence time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normalized = normalize(x_train, norm='l2')\n",
    "x_test_normalized = normalize(x_test, norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is then trained with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 0.5, 1, 2, 5, 100, 1000], 'kernel': ['linear', 'poly', 'rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(x_train_normalized, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation score and some other statistics are then calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCORES FOR SVM:\n",
      "\n",
      "Gridsearch CV score: 0.997046596445\n",
      "Training set score:  0.997087403402\n",
      "Linear accuracy score:  0.997470007345\n",
      "Best Parameters Selected:  {'C': 1000, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"SCORES FOR SVM:\")\n",
    "print(\"\")\n",
    "print(\"Gridsearch CV score:\", svm.best_score_)\n",
    "print(\"Training set score: \", svm.score(x_train_normalized, y_train))\n",
    "print(\"Linear accuracy score: \", svm.score(x_test_normalized, y_test))\n",
    "print(\"Best Parameters Selected: \", svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, GridSearchCV selects C = 1000 and a rbf kernel as the best parameters. Thus a Hard Margin SVM gives the best results for this data. The test data is then used to predict and calculate the final model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = svm.predict(x_test_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score and the confusion matrix for the model are then obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the prediction:  0.997470007345\n",
      "Confusion Matrix:\n",
      "[[10337    11]\n",
      " [  113 38551]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for the prediction: \", accuracy_score(y_test, svm_predictions))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernelized Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A modified version of Kernalized Ridge Regression is then attempted where the results are normalized so as to be applicable for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernreg = KernelRidge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a non-linear model, the data is normalized to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normalized = normalize(x_train, norm='l2')\n",
    "x_test_normalized = normalize(x_test, norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV is then used to conduct 5-fold cross validation and to select between the hyperparameters specified in the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = GridSearchCV(kernreg, cv=5, param_grid=[{'kernel': ['linear']}, {'alpha': [1], 'kernel': ['poly'], 'gamma': [1], 'degree': [2, 3]}, {'kernel': ['rbf'], 'gamma': [0.1, 0.5, 1, 2, 4]}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is then trained with the training data and the hyperparameters selected by GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.fit(x_train_normalized, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation score, the best hyperparameters selected and some other statistics are then obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"SCORES FOR KERNALIZED RIDGE:\")\n",
    "print(\"\")\n",
    "print(\"Gridsearch CV score: \", ridge.best_score_)\n",
    "print(\"Training set score: \", ridge.score(x_train_normalized, y_train))\n",
    "print(\"Linear accuracy score: \", ridge.score(x_test_normalized, y_test))\n",
    "print(\"Best Parameters Selected: \", ridge.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then predict the class and normalize the results to obtain the accuracy score and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_predictions = ridge.predict(x_test_normalized)\n",
    "ridge_predictions = ridge_predictions.tolist()\n",
    "for i in range(0, len(ridge_predictions), 1):\n",
    "\tif ridge_predictions[i] < 1 or ridge_predictions[i] > 1.5 or ridge_predictions[i] > 2.5:\n",
    "\t\tridge_predictions[i] = ceil(ridge_predictions[i])\n",
    "\telse:\n",
    "\t\tridge_predictions[i] = floor(ridge_predictions[i])\n",
    "\n",
    "ridge_predictions = np.asarray(ridge_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score and confusion matrix for the prediction are then obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score for the prediction: \", accuracy_score(y_test, ridge_predictions))\n",
    "print(\"Confusion Matrix:\") \n",
    "print(confusion_matrix(y_test, ridge_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was left to train for over 12 hours in Jupyter notebook but still didn't complete training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After observing the prediction results and accuracy scores of the above models, it is concluded that Hard Margin SVM with a gaussian kernel and C = 1000 gives the best results with this dataset. Its accuracy score is 0.997470007345. The accuracy score is a measure of the correct predictions made in comparision to the total number of predictions made. The confusion matrix on the other hand, is a matrix which shows the actual predictions on the x axis and the accuracy on the y axis. The cells represent the total number of predictions made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
